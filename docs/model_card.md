# Model Card:

## Overview

**Model name:** SSL for Alzheimer's  
**Model type:** Convolutional neural network encoder trained via self-supervised contrastive learning  
**Training framework:** SimCLR (Simple Framework for Contrastive Learning of Visual Representations)  
**Backbone architecture:** ResNet-50  
**Framework:** PyTorch  

This model learns useful and meaningful representations from the unlabeled brain MRI scans using self-supervised learning method. The pretrained encoder is later fine-tuned with limited labeled data for neurological brain disease classification tasks.


## Intended Use

### Intended Use
- Research and educational purposes
- Brain MRI representation learning
- Low-label neurological disease classification
- Model interpretability research using visual explanations (Grad-CAM)

### Not Intended Use
- Clinical diagnosis
- Medical decision-making
- Replacement for professional medical judgment


## Training Data

- **Unlabeled data:** Publicly available, de-identified brain MRI datasets (e.g OASIS)
- **Labeled data (fine-tuning):**
  - Alzheimer’s Disease (4-class classification)
  - Brain Tumor (4-class classification)
  - Parkinson’s Disease (2-class classification) 
  - Multiple Sclerosis (2-class classification)

All datasets used are publicly available and intended for research use only.


## Training Procedure

1. SSL pretraining using SimCLR method
2. Contrastive learning with NT-Xent loss
3. Medically safe augmentations (random crop, horizontal flip, brightness adjustment, grayscale)
4. ResNet-50 encoder with a projection head during training
5. Fine-tuning with limited labeled samples
6. Evaluation of Alzheimers and other neurological diseases
7. Explainability via Grad-CAM visualizations and metrics.

The full pipeline is implemented in a single reproducible Jupyter notebook.


## Evaluation Metrics

- Classification Accuracy
- Precision, Recall, and F1-score
- Confusion Matrix
- Grad-CAM visual explanations with Confidence Score
- Activation Intensity and Activation Area metrics (explainability)

The SSL for Alzheimer's model significantly outperformed a regular supervised ResNet-50 baseline in low-label settings.


## Explainability and Transparency

- Heatmaps generated by Grad-CAM highlight the important regions in the brain that contributes to the final predictions.
- The Activation Intensity and Activation Area metrics provide visual information via boundaries and region selected.
- The visual metrics explains and matches well with anatomical patterns of the brain.


## Limitations

- Performance depends on the quality and consistency of MRI images.
- The MRI scans in the public datasets are not diverse.
- It may be biased if the dataset is highly imbalanced.
- Not tested on patient data for real-world deployment


## Ethical Considerations

- This project uses MRI scans from the publicly available datasets.
- No personal identifiable information is being used.
- The project focuses on research aspect and not clinical diagnosis yet.
- Emphasizes transparency and interpretability to reduce black-box risks in healthcare AI

## Model Availability

- Code and pretrained weights are available via GitHub
- End-to-end training and inference pipeline provided in 'Hack4Health.ipynb'

